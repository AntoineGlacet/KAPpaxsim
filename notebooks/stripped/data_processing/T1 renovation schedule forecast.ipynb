{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8924977",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Process the original file to match function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4b682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:37:14.546636Z",
     "start_time": "2021-06-24T09:37:05.868529Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# to auto-reload the imports\n",
    "# if we change something in our functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext nb_black\n",
    "\n",
    "# import the libraries required to do the work\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "from src.utils.sharepoint import get_T1_ren_6kPax_schedule\n",
    "from decouple import AutoConfig\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4cbfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:37:19.299685Z",
     "start_time": "2021-06-24T09:37:17.780076Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the schedule from Sharepoint\n",
    "get_T1_ren_6kPax_schedule()\n",
    "\n",
    "# get the paths to config (could be made as a function for notebooks)\n",
    "\n",
    "DOTENV_FILE_PATH = Path(os.getcwd()) / \"../../../data/secret/.env\"\n",
    "config = AutoConfig(search_path=DOTENV_FILE_PATH)\n",
    "\n",
    "path_relative = config(\"T1_ren_6kPax_schedule_path\")\n",
    "\n",
    "path_data = Path(os.getcwd()) / \"..\" / \"..\" / \"..\" / path_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2866ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:37:23.047037Z",
     "start_time": "2021-06-24T09:37:22.654038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define a function to insert space in flight number\n",
    "def insert_space_after_letters(test_str: str):\n",
    "    res = re.sub(\"[A-Za-z]+\", lambda ele: ele[0] + \" \", test_str)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb02edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:05.132754Z",
     "start_time": "2021-06-24T10:03:03.406757Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the schedule from the excel file produced by Aero department\n",
    "data_arr = pd.read_excel(\n",
    "    path_data,\n",
    "    header=0,\n",
    "    sheet_name=\"ARR\",\n",
    ")\n",
    "\n",
    "data_dep = pd.read_excel(\n",
    "    path_data,\n",
    "    header=0,\n",
    "    sheet_name=\"DEP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff2fe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:10.504753Z",
     "start_time": "2021-06-24T10:03:10.006756Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# edit data to match application format\n",
    "data_arr_processed = data_arr.copy()\n",
    "data_arr_processed[\"A/D\"] = \"A\"\n",
    "data_arr_processed[\"T1/T2(MM/9C/7C/TW)\"] = \"T1\"\n",
    "data_arr_processed[\"Int'l Regions\"] = \"unknown\"\n",
    "\n",
    "dct_name_change = {\n",
    "    \"貨客区分\": \"Category(P/C/O)\",\n",
    "    \"DI区分\": \"Sector\",\n",
    "    \"航空機識別\": \"Flight Number\",  # <- to be split with space between letters and digits\n",
    "    \"座席数\": \"SEATS FC\",\n",
    "    \"搭乗者数\": \"Pax_SUM FC\",\n",
    "    \"到着予定日\": \"Flight Date\",\n",
    "    \"STA\": \"Scheduled Time\",\n",
    "}\n",
    "\n",
    "data_arr_processed.rename(columns=dct_name_change, inplace=True)\n",
    "\n",
    "data_arr_processed[\"Flight Number\"] = data_arr_processed[\"Flight Number\"].apply(\n",
    "    insert_space_after_letters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa637d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:16.311756Z",
     "start_time": "2021-06-24T10:03:15.670755Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# problem : no Seats and Pax number for arrival flights...\n",
    "# keep only relevant columns\n",
    "# data_arr_processed = data_arr_processed[\n",
    "#    [\n",
    "#        \"A/D\",\n",
    "#        \"T1/T2(MM/9C/7C/TW)\",\n",
    "#        \"Int'l Regions\",\n",
    "#        \"Category(P/C/O)\",\n",
    "#        \"Sector\",\n",
    "#        \"Flight Number\",\n",
    "#        \"SEATS FC\",\n",
    "#        \"Pax_SUM FC\",\n",
    "#        \"Flight Date\",\n",
    "#        \"Scheduled Time\",\n",
    "#    ]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744a334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:23.073754Z",
     "start_time": "2021-06-24T10:03:22.226757Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# edit data to match application format\n",
    "data_dep_processed = data_dep.copy()\n",
    "data_dep_processed[\"A/D\"] = \"D\"\n",
    "data_dep_processed[\"T1/T2(MM/9C/7C/TW)\"] = \"T1\"\n",
    "data_dep_processed[\"Intl Regions\"] = \"unknown\"\n",
    "\n",
    "dct_name_change = {\n",
    "    \"貨客区分\": \"Category(P/C/O)\",\n",
    "    \"DI区分\": \"Sector\",\n",
    "    \"航空機識別\": \"Flight Number\",  # <- to be split with space between letters and digits\n",
    "    \"座席数\": \"SEATS FC\",\n",
    "    \"搭乗者数\": \"PAX_SUM FC\",\n",
    "    \"出発予定日\": \"Flight Date\",\n",
    "    \"STD\": \"Scheduled Time\",\n",
    "}\n",
    "\n",
    "data_dep_processed.rename(columns=dct_name_change, inplace=True)\n",
    "\n",
    "data_dep_processed[\"Flight Number\"] = data_dep_processed[\"Flight Number\"].apply(\n",
    "    insert_space_after_letters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231a431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:28.652204Z",
     "start_time": "2021-06-24T10:03:28.228202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# keep only relevant columns\n",
    "data_dep_processed = data_dep_processed[\n",
    "    [\n",
    "        \"A/D\",\n",
    "        \"T1/T2(MM/9C/7C/TW)\",\n",
    "        \"Intl Regions\",\n",
    "        \"Category(P/C/O)\",\n",
    "        \"Sector\",\n",
    "        \"Flight Number\",\n",
    "        \"SEATS FC\",\n",
    "        \"PAX_SUM FC\",\n",
    "        \"Flight Date\",\n",
    "        \"Scheduled Time\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# correct input mistake (?)\n",
    "mask_replace = data_dep_processed[\"PAX_SUM FC\"] == \"-\"\n",
    "data_dep_processed.loc[mask_replace, \"PAX_SUM FC\"] = 0\n",
    "\n",
    "mask_replace = data_dep_processed[\"SEATS FC\"] == \"-\"\n",
    "data_dep_processed.loc[mask_replace, \"SEATS FC\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5a062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:33.764008Z",
     "start_time": "2021-06-24T10:03:33.171010Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we should add a step to merge the two in one\n",
    "# as we do not have seats and Pax for T1 schedule, let's forget about it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716bf4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:39.944647Z",
     "start_time": "2021-06-24T10:03:38.818902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    Path(os.getcwd())\n",
    "    / \"../../../data/processed/Schedule (30th terminal peak, 6000 pax)_PROCESSED.xlsx\"\n",
    ")\n",
    "\n",
    "writer = pd.ExcelWriter(\n",
    "    output_path,\n",
    "    engine=\"xlsxwriter\",\n",
    ")\n",
    "\n",
    "with writer as writer:\n",
    "    data_dep_processed.to_excel(writer, sheet_name=\"schedule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85227987",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# rewrite show-up fuinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21270be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:45:21.577821Z",
     "start_time": "2021-06-24T09:45:21.135348Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "the input schedule must have the format as per template.\n",
    "the sheet_name should be \"schedule\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8177a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:51:56.810924Z",
     "start_time": "2021-06-24T09:51:56.394926Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_mask = (\n",
    "    (data_dep_processed[\"A/D\"] == direction)\n",
    "    & (data_dep_processed[\"Sector\"] == sector)\n",
    "    & (data_dep_processed[\"Category(P/C/O)\"] == \"P\")\n",
    "    & (data_dep_processed[\"T1/T2(MM/9C/7C/TW)\"] == terminal)\n",
    "    & (data_dep_processed[\"Flight Date\"] == pd.Timestamp(date_str))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeffd8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:02:24.247887Z",
     "start_time": "2021-06-24T10:02:23.834454Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dep_processed[\"SEATS FC\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed7539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:54:52.342196Z",
     "start_time": "2021-06-24T09:54:48.534050Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_, df_Pax = show_up_from_schedule(\n",
    "    path_to_schedule=output_path,\n",
    "    direction=\"D\",\n",
    "    sector=\"I\",\n",
    "    terminal=\"T1\",\n",
    "    system=\"terminal\",\n",
    "    date_str=\"2017-03-19\",\n",
    "    custom_showup=False,\n",
    "    custom_counter_rule=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ea72e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:03:52.448677Z",
     "start_time": "2021-06-24T10:03:44.904685Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_Counters = show_up_from_schedule(\n",
    "    path_to_schedule=output_path,\n",
    "    direction=\"D\",\n",
    "    sector=\"I\",\n",
    "    terminal=\"T1\",\n",
    "    system=\"check-in\",\n",
    "    date_str=\"2017-03-19\",\n",
    "    custom_showup=False,\n",
    "    custom_counter_rule=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d829b90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:09:28.551223Z",
     "start_time": "2021-06-24T10:09:28.070424Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87ce27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:34:50.594594Z",
     "start_time": "2021-06-24T10:34:49.828428Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_Pax[\"N\"] = 1\n",
    "plot = df_Pax.set_index(\"time\", drop=False)[[\"N\"]].resample(\"5min\").agg(\"sum\") * 12\n",
    "plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbc268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:34:44.966247Z",
     "start_time": "2021-06-24T10:34:44.242772Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_Counters[\"total\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0a58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:48:28.617945Z",
     "start_time": "2021-06-24T09:48:27.552947Z"
    },
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_up_from_schedule(\n",
    "    path_to_schedule:pathlib.Path,\n",
    "    direction:str=\"D\",\n",
    "    sector:str=\"I\",\n",
    "    terminal:str=\"T1\",\n",
    "    system:str=\"terminal\",\n",
    "    date_str:str=\"2017-03-19\",\n",
    "    custom_showup:bool=False,\n",
    "    custom_counter_rule:bool=False,\n",
    "):\n",
    "\n",
    "    # =============================== preparatory work for all peak hour extractions============================================\n",
    "\n",
    "    # give the paths to schedule forecast and show-up profiles\n",
    "    # we also use the \"airline code\" sheet for show-up profiles\n",
    "    # get env variables (for schedule and show-up files paths)\n",
    "    DOTENV_FILE_PATH = Path(os.getcwd()) / \"../../../data/secret/.env\"\n",
    "    config = AutoConfig(search_path=DOTENV_FILE_PATH)\n",
    "\n",
    "    path_forecasts = path_to_schedule\n",
    "\n",
    "    path_show_up = (\n",
    "        Path(os.getcwd()) / \"..\" / \"..\" / \"..\" / config(\"ADRM_param_full_path\")\n",
    "    )\n",
    "\n",
    "    # import the airline_code\n",
    "    airline_code = pd.read_excel(\n",
    "        path_show_up,\n",
    "        sheet_name=r\"airline_code\",\n",
    "        header=0,\n",
    "    )\n",
    "\n",
    "    # if custom showup, assign the mean and STD\n",
    "    if custom_showup == True:\n",
    "        loc_FSC = kwargs[\"loc_FSC\"]\n",
    "        scale_FSC = kwargs[\"scale_FSC\"]\n",
    "        loc_LCC = kwargs[\"loc_LCC\"]\n",
    "        scale_LCC = kwargs[\"scale_LCC\"]\n",
    "        loc_CHINA = kwargs[\"loc_CHINA\"]\n",
    "        scale_CHINA = kwargs[\"scale_CHINA\"]\n",
    "        loc_EARLY = kwargs[\"loc_EARLY\"]\n",
    "        scale_EARLY = kwargs[\"scale_EARLY\"]\n",
    "\n",
    "    # import the schedule from the excel file produced by Aero department\n",
    "    data = pd.read_excel(\n",
    "        path_forecasts,\n",
    "        sheet_name=r\"schedule\",\n",
    "        header=0,\n",
    "    )\n",
    "\n",
    "    # format a Schedules time column to make a Timeserie later on\n",
    "\n",
    "    data[\"Scheduled Time\"] = \"2020-10-13 \" + data[\"Scheduled Time\"].astype(str)\n",
    "    data[\"Scheduled Time\"] = pd.to_datetime(data[\"Scheduled Time\"])\n",
    "\n",
    "    data[\"Flight Number\"] = data[\"Flight Number\"].replace([\"JX821\"], \"JX 821\")\n",
    "\n",
    "    # ===========================================  function start ================================================\n",
    "    # filter\n",
    "    filtered_data = data[\n",
    "        (\n",
    "            (data[\"A/D\"] == direction)\n",
    "            & (data[\"Sector\"] == sector)\n",
    "            & (data[\"Category(P/C/O)\"] == \"P\")\n",
    "            & (data[\"T1/T2(MM/9C/7C/TW)\"] == terminal)\n",
    "            & (data[\"Flight Date\"] == pd.Timestamp(date_str))\n",
    "        )\n",
    "    ]\n",
    "    filtered_data = filtered_data.reset_index()\n",
    "    data = filtered_data\n",
    "    # ====================================== Counters =====================================\n",
    "    if system == \"check-in\":\n",
    "        # NEW fix some input mistakes\n",
    "        data[\"Flight Number\"] = data[\"Flight Number\"].replace([\"JX821\"], \"JX 821\")\n",
    "        data[\"Flight Number\"] = data[\"Flight Number\"].replace([\"NS*****\"], \"NS *****\")\n",
    "        # split Airline Code\n",
    "        data[\"Airline Code\"] = data[\"Flight Number\"].str.split(\" \", 1, expand=True)[0]\n",
    "\n",
    "        # NEW\n",
    "        start_time = 2.5  # hours before STD for check-in opening\n",
    "        onecounter_time = 0.75  # hours before STD with only one counter\n",
    "        base_n_counter = 4\n",
    "        seats_per_add_counter = 60\n",
    "\n",
    "        # in case we change checkin counter allocation rule\n",
    "        if custom_counter_rule == True:\n",
    "            start_time = kwargs[\"start_time\"]\n",
    "            onecounter_time = kwargs[\"onecounter_time\"]\n",
    "            base_n_counter = kwargs[\"base_n_counter\"]\n",
    "            seats_per_add_counter = kwargs[\"seats_per_add_counter\"]\n",
    "\n",
    "        onecounter_slot = -int(((onecounter_time) * 60) // 5)\n",
    "        start_slot = -int(((start_time) * 60) // 5)\n",
    "\n",
    "        # create a dictionnary of airline and seats per 5 minutes\n",
    "        # initialize with all {airline_code : [0...0]}\n",
    "        dico = {\n",
    "            airline_code: [0 for i in range(int(24 * 60 / 5))]\n",
    "            for airline_code in data[\"Airline Code\"]\n",
    "        }\n",
    "\n",
    "        # boucle sur les airlines\n",
    "        for airline_code in data[\"Airline Code\"].unique():\n",
    "\n",
    "            # boucle sur les flight code\n",
    "            for flight_number in data[(data[\"Airline Code\"] == airline_code)][\n",
    "                \"Flight Number\"\n",
    "            ]:\n",
    "\n",
    "                # round down 5 minutes le STD\n",
    "                time = data[data[\"Flight Number\"] == flight_number][\n",
    "                    \"Scheduled Time\"\n",
    "                ].iloc[0]\n",
    "                STD_5interval = (time.hour * 60 + time.minute) // 5\n",
    "\n",
    "                # on met le nombre de seats du vol à la position qui va bien dans les listes du dico\n",
    "                dico[airline_code][STD_5interval] = (\n",
    "                    dico[airline_code][STD_5interval]\n",
    "                    + data[\n",
    "                        (data[\"Scheduled Time\"] == time)\n",
    "                        & (data[\"Flight Number\"] == flight_number)\n",
    "                    ][\"SEATS FC\"].iloc[0]\n",
    "                )\n",
    "\n",
    "        df_Seats = pd.DataFrame.from_dict(dico)\n",
    "\n",
    "        # initialize some dataframes\n",
    "        df_Counters = pd.DataFrame().reindex_like(df_Seats)\n",
    "        for col in df_Counters.columns:\n",
    "            df_Counters[col].values[:] = int(0)\n",
    "\n",
    "        # create a df over 3 days to avoid errors for flights close to midnight\n",
    "        df_Counters_previous_day = df_Counters.copy()\n",
    "        df_Counters_next_day = df_Counters.copy()\n",
    "        df_Counters_previous_day = df_Counters_previous_day.reindex(\n",
    "            index=[\"day-1 {}\".format(i) for i in range(0, 288)]\n",
    "        )\n",
    "        df_Counters_next_day = df_Counters_next_day.reindex(\n",
    "            index=[\"day+1 {}\".format(i) for i in range(0, 288)]\n",
    "        )\n",
    "\n",
    "        df1 = df_Counters_previous_day\n",
    "        df2 = df_Counters\n",
    "        df3 = df_Counters_next_day\n",
    "\n",
    "        df_Counters_3d = df1.append(df2).append(df3)\n",
    "        df_Counters_3d = df_Counters_3d.fillna(0)\n",
    "\n",
    "        offset = 288\n",
    "\n",
    "        # First we add the seats for 2.5 hours before STD\n",
    "        # to 45 min before STD\n",
    "        for col in range(len(df_Seats.columns)):\n",
    "            for i in range(len(df_Seats.index)):\n",
    "                # When we see a cell with Seats for a flight\n",
    "                if df_Seats.iloc[i, col] != 0:\n",
    "                    # Wee check from 45 minutes to 2.5 hours before STD\n",
    "                    for j in range(start_slot, onecounter_slot):\n",
    "                        # for each cell, if there is already a number, we put add the seats\n",
    "                        df_Counters_3d.iloc[i + offset + j, col] = (\n",
    "                            df_Counters_3d.iloc[i + offset + j, col]\n",
    "                            + df_Seats.iloc[i, col]\n",
    "                        )\n",
    "        # now we have a table with seats, let's apply the rule\n",
    "        # valid on that period\n",
    "        for col in range(len(df_Counters_3d.columns)):\n",
    "            for i in range(len(df_Counters_3d.index)):\n",
    "                if 0 < df_Counters_3d.iloc[i, col]:\n",
    "                    df_Counters_3d.iloc[i, col] = max(\n",
    "                        base_n_counter,\n",
    "                        base_n_counter\n",
    "                        + (\n",
    "                            (df_Counters_3d.iloc[i, col] - 200) // seats_per_add_counter\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "        # Then we do the last 45 minutes\n",
    "\n",
    "        for col in range(len(df_Seats.columns)):\n",
    "            for i in range(len(df_Seats.index)):\n",
    "                # When we see a cell with Seats for a flight\n",
    "                if df_Seats.iloc[i, col] != 0:\n",
    "                    # we check from STD to 45 minutes before\n",
    "                    for j in range(onecounter_slot, 1):\n",
    "                        # only if no other flights are checking in, do we add a counter\n",
    "                        if df_Counters_3d.iloc[i + offset + j, col] == 0:\n",
    "                            df_Counters_3d.iloc[i + offset + j, col] = 1\n",
    "\n",
    "        # merge into only 1d\n",
    "        df_Counters_final = df_Counters.copy()\n",
    "        for i in range(len(df_Counters_final.index)):\n",
    "            df_Counters_final.iloc[i, :] = (\n",
    "                df_Counters_3d.iloc[i, :]\n",
    "                + df_Counters_3d.iloc[i + offset, :]\n",
    "                + df_Counters_3d.iloc[i + 2 * offset, :]\n",
    "            )\n",
    "        df_Counters_final[\"total\"] = df_Counters_final.sum(axis=1)\n",
    "\n",
    "    # now we do all the show-up\n",
    "\n",
    "    # ====================================== Terminal =====================================\n",
    "    # For Terminal\n",
    "    if system == \"terminal\":\n",
    "        # import of the excel with the show up profiles\n",
    "        show_up_ter = pd.read_excel(\n",
    "            path_show_up,\n",
    "            sheet_name=r\"terminal\",\n",
    "            header=1,\n",
    "        )\n",
    "        show_up_ter = show_up_ter.drop([0, 1], axis=0)\n",
    "        show_up_ter = show_up_ter.reset_index(drop=True)\n",
    "\n",
    "        # interpolation of show_up profiles and inverse functions\n",
    "        x = show_up_ter[\"time before STD\"].to_numpy(dtype=float)\n",
    "\n",
    "        yFSC = show_up_ter[\"cumulative distribution FSC\"].to_numpy(dtype=float)\n",
    "        yLCC = show_up_ter[\"cumulative distribution LCC\"].to_numpy(dtype=float)\n",
    "        yEARLY = show_up_ter[\"cumulative distribution EARLY\"].to_numpy(dtype=float)\n",
    "        yCHINA = show_up_ter[\"cumulative distribution CHINA\"].to_numpy(dtype=float)\n",
    "\n",
    "        f_ter_FSC = interp1d(x, yFSC, kind=\"linear\")\n",
    "        f_ter_LCC = interp1d(x, yLCC, kind=\"linear\")\n",
    "        f_ter_EARLY = interp1d(x, yEARLY, kind=\"linear\")\n",
    "        f_ter_CHINA = interp1d(x, yCHINA, kind=\"linear\")\n",
    "\n",
    "        if custom_showup == True:\n",
    "            f_ter_FSC = lambda x: 1 - norm.cdf(x, loc=loc_FSC, scale=scale_FSC)\n",
    "            f_ter_LCC = lambda x: 1 - norm.cdf(x, loc=loc_LCC, scale=scale_LCC)\n",
    "            f_ter_EARLY = lambda x: 1 - norm.cdf(x, loc=loc_EARLY, scale=scale_EARLY)\n",
    "            f_ter_CHINA = lambda x: 1 - norm.cdf(x, loc=loc_CHINA, scale=scale_CHINA)\n",
    "\n",
    "        f_ter_FSC_inv_linear = interp1d(f_ter_FSC(x), x, kind=\"linear\")\n",
    "        f_ter_LCC_inv_linear = interp1d(f_ter_LCC(x), x, kind=\"linear\")\n",
    "        f_ter_EARLY_inv_linear = interp1d(f_ter_EARLY(x), x, kind=\"linear\")\n",
    "        f_ter_CHINA_inv_linear = interp1d(f_ter_CHINA(x), x, kind=\"linear\")\n",
    "\n",
    "        # let's allocate profiles to flight\n",
    "        list_time_Pax = []\n",
    "        list_flights = []\n",
    "        list_ST = []\n",
    "        for i in range(len(filtered_data)):\n",
    "            N_flight_pax = int(filtered_data.loc[i, \"PAX_SUM FC\"])\n",
    "            STD = filtered_data.loc[i, \"Scheduled Time\"]\n",
    "            y = np.linspace(0.0001, 0.995, N_flight_pax)\n",
    "\n",
    "            if filtered_data.loc[i, \"Scheduled Time\"] < pd.to_datetime(\n",
    "                \"2020-10-13 08:00:00\"\n",
    "            ) and filtered_data.loc[i, \"Scheduled Time\"] >= pd.to_datetime(\n",
    "                \"2020-10-13 02:00:00\"\n",
    "            ):\n",
    "                temps_Terminal = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_ter_EARLY_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            elif filtered_data.loc[i, \"Intl Regions\"] == \"China\":\n",
    "                temps_Terminal = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_ter_CHINA_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            elif filtered_data.loc[i, \"Flight Number\"][0:2] in airline_code[\n",
    "                airline_code[\"FSC / LCC\"] == \"FSC\"\n",
    "            ][\"airline code\"].to_numpy(dtype=\"str\"):\n",
    "                temps_Terminal = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_ter_LCC_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                temps_Terminal = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_ter_FSC_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            for t in temps_Terminal:\n",
    "                t = datetime.datetime(\n",
    "                    year=2020,\n",
    "                    month=10,\n",
    "                    day=13,\n",
    "                    hour=int((t % (24 * 60)) / 60),\n",
    "                    minute=int(t % 60),\n",
    "                    second=int(t % 1 * 60),\n",
    "                )\n",
    "                list_time_Pax.append(t)\n",
    "                list_flights.append(filtered_data.loc[i, \"Flight Number\"])\n",
    "                list_ST.append(filtered_data.loc[i, \"Scheduled Time\"])\n",
    "\n",
    "    # ====================================== Security =====================================\n",
    "    # For Security\n",
    "    if system == \"security\":\n",
    "        # import of the excel with the show up profiles\n",
    "        show_up_sec = pd.read_excel(\n",
    "            path_show_up,\n",
    "            sheet_name=r\"PRS\",\n",
    "            header=1,\n",
    "        )\n",
    "        show_up_sec = show_up_sec.drop([0, 1], axis=0)\n",
    "        show_up_sec = show_up_sec.reset_index(drop=True)\n",
    "\n",
    "        # interpolation of show_up profiles and inverse functions\n",
    "        x = show_up_sec[\"time before STD\"].to_numpy(dtype=float)\n",
    "\n",
    "        yFSC = show_up_sec[\"cumulative distribution FSC\"].to_numpy(dtype=float)\n",
    "        f_sec_FSC = interp1d(x, yFSC, kind=\"linear\")\n",
    "\n",
    "        yLCC = show_up_sec[\"cumulative distribution LCC\"].to_numpy(dtype=float)\n",
    "        f_sec_LCC = interp1d(x, yLCC, kind=\"linear\")\n",
    "\n",
    "        yEARLY = show_up_sec[\"cumulative distribution EARLY\"].to_numpy(dtype=float)\n",
    "        f_sec_EARLY = interp1d(x, yEARLY, kind=\"linear\")\n",
    "\n",
    "        yCHINA = show_up_sec[\"cumulative distribution CHINA\"].to_numpy(dtype=float)\n",
    "        f_sec_CHINA = interp1d(x, yEARLY, kind=\"linear\")\n",
    "\n",
    "        yMORNING = show_up_sec[\"cumulative distribution MORNING\"].to_numpy(dtype=float)\n",
    "        f_sec_MORNING = interp1d(x, yEARLY, kind=\"linear\")\n",
    "\n",
    "        f_sec_FSC = interp1d(x, yFSC, kind=\"linear\")\n",
    "        f_sec_LCC = interp1d(x, yLCC, kind=\"linear\")\n",
    "        f_sec_EARLY = interp1d(x, yEARLY, kind=\"linear\")\n",
    "        f_sec_CHINA = interp1d(x, yCHINA, kind=\"linear\")\n",
    "        f_sec_MORNING = interp1d(x, yMORNING, kind=\"linear\")\n",
    "\n",
    "        f_sec_FSC_inv_linear = interp1d(f_sec_FSC(x), x, kind=\"linear\")\n",
    "        f_sec_LCC_inv_linear = interp1d(f_sec_LCC(x), x, kind=\"linear\")\n",
    "        f_sec_EARLY_inv_linear = interp1d(f_sec_EARLY(x), x, kind=\"linear\")\n",
    "        f_sec_CHINA_inv_linear = interp1d(f_sec_CHINA(x), x, kind=\"linear\")\n",
    "        f_sec_MORNING_inv_linear = interp1d(f_sec_MORNING(x), x, kind=\"linear\")\n",
    "\n",
    "        # let's allocate profiles to flight\n",
    "        list_time_Pax = []\n",
    "        list_flights = []\n",
    "        list_ST = []\n",
    "        for i in range(len(filtered_data)):\n",
    "            N_flight_pax = int(filtered_data.loc[i, \"PAX_SUM FC\"])\n",
    "            STD = filtered_data.loc[i, \"Scheduled Time\"]\n",
    "            y = np.linspace(0.0001, 0.995, N_flight_pax)\n",
    "\n",
    "            if filtered_data.loc[i, \"Scheduled Time\"] < pd.to_datetime(\n",
    "                \"2020-10-13 08:00:00\"\n",
    "            ) and filtered_data.loc[i, \"Scheduled Time\"] >= pd.to_datetime(\n",
    "                \"2020-10-13 02:00:00\"\n",
    "            ):\n",
    "                temps_Security = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_sec_EARLY_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            elif filtered_data.loc[i, \"Scheduled Time\"] < pd.to_datetime(\n",
    "                \"2020-10-13 12:00:00\"\n",
    "            ) and filtered_data.loc[i, \"Scheduled Time\"] >= pd.to_datetime(\n",
    "                \"2020-10-13 08:00:00\"\n",
    "            ):\n",
    "                temps_Security = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_sec_MORNING_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            elif filtered_data.loc[i, \"Intl Regions\"] == \"China\":\n",
    "                temps_Security = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_sec_CHINA_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            elif filtered_data.loc[i, \"Flight Number\"][0:2] in airline_code[\n",
    "                airline_code[\"FSC / LCC\"] == \"FSC\"\n",
    "            ][\"airline code\"].to_numpy(dtype=\"str\"):\n",
    "                temps_Security = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_sec_LCC_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                temps_Security = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_sec_FSC_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            for t in temps_Security:\n",
    "                t = datetime.datetime(\n",
    "                    year=2020,\n",
    "                    month=10,\n",
    "                    day=13,\n",
    "                    hour=int((t % (24 * 60)) / 60),\n",
    "                    minute=int(t % 60),\n",
    "                    second=int(t % 1 * 60),\n",
    "                )\n",
    "                list_time_Pax.append(t)\n",
    "                list_flights.append(filtered_data.loc[i, \"Flight Number\"])\n",
    "                list_ST.append(filtered_data.loc[i, \"Scheduled Time\"])\n",
    "\n",
    "    # ====================================== Call to Gate =====================================\n",
    "    if system == \"CTG\":\n",
    "        # import of the excel with the show up profiles\n",
    "        show_up_CTG = pd.read_excel(\n",
    "            path_show_up,\n",
    "            sheet_name=r\"CTG\",\n",
    "            header=1,\n",
    "        )\n",
    "        show_up_CTG = show_up_CTG.drop([0, 1, 2], axis=0)\n",
    "        show_up_CTG = show_up_CTG.reset_index(drop=True)\n",
    "\n",
    "        # interpolation of CTG profiles for specified type and inverse functions\n",
    "        x = show_up_CTG[\"time before STD\"].to_numpy(dtype=float)\n",
    "\n",
    "        y_CTG_C = show_up_CTG[\n",
    "            \"cumulative distribution code C type {}\".format(CTG_type)\n",
    "        ].to_numpy(dtype=float)\n",
    "        y_CTG_E = show_up_CTG[\n",
    "            \"cumulative distribution code E type {}\".format(CTG_type)\n",
    "        ].to_numpy(dtype=float)\n",
    "        f_CTG_C = interp1d(x, y_CTG_C, kind=\"linear\")\n",
    "        f_CTG_E = interp1d(x, y_CTG_E, kind=\"linear\")\n",
    "\n",
    "        f_CTG_C_inv_linear = interp1d(f_CTG_C(x), x, kind=\"linear\")\n",
    "        f_CTG_E_inv_linear = interp1d(f_CTG_E(x), x, kind=\"linear\")\n",
    "\n",
    "        # let's allocate profiles to flight\n",
    "        list_time_Pax = []\n",
    "        list_flights = []\n",
    "        list_ST = []\n",
    "        for i in range(len(filtered_data)):\n",
    "            N_flight_pax = int(filtered_data.loc[i, \"PAX_SUM FC\"])\n",
    "            STD = filtered_data.loc[i, \"Scheduled Time\"]\n",
    "            y = np.linspace(0.0001, 0.995, N_flight_pax)\n",
    "\n",
    "            if filtered_data.loc[i, \"Aircraft_Narrow/Wide\"] == \"Narrow body\":\n",
    "                temps_CTG = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_CTG_C_inv_linear(y)\n",
    "                )\n",
    "            else:\n",
    "                temps_CTG = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_CTG_E_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            for t in temps_CTG:\n",
    "                t = datetime.datetime(\n",
    "                    year=2020,\n",
    "                    month=10,\n",
    "                    day=13,\n",
    "                    hour=int((t % (24 * 60)) / 60),\n",
    "                    minute=int(t % 60),\n",
    "                    second=int(t % 1 * 60),\n",
    "                )\n",
    "                list_time_Pax.append(t)\n",
    "                list_flights.append(filtered_data.loc[i, \"Flight Number\"])\n",
    "                list_ST.append(filtered_data.loc[i, \"Scheduled Time\"])\n",
    "\n",
    "    # ====================================== Boarding =====================================\n",
    "    if system == \"boarding\":\n",
    "        # import of the excel with the show up profiles\n",
    "        show_up_boarding = pd.read_excel(\n",
    "            path_show_up,\n",
    "            sheet_name=r\"boarding\",\n",
    "            header=0,\n",
    "        )\n",
    "        show_up_boarding = show_up_boarding.reset_index(drop=True)\n",
    "\n",
    "        # interpolation of boarding profiles for specified type and inverse functions\n",
    "        x = show_up_boarding[\"time before STD\"].to_numpy(dtype=float)\n",
    "\n",
    "        y_boarding_C = show_up_boarding[\"cumulative distribution code C\"].to_numpy(\n",
    "            dtype=float\n",
    "        )\n",
    "        y_boarding_E = show_up_boarding[\"cumulative distribution code E\"].to_numpy(\n",
    "            dtype=float\n",
    "        )\n",
    "        f_boarding_C = interp1d(x, y_boarding_C, kind=\"linear\")\n",
    "        f_boarding_E = interp1d(x, y_boarding_E, kind=\"linear\")\n",
    "\n",
    "        f_boarding_C_inv_linear = interp1d(\n",
    "            f_boarding_C(x)[0:10], x[0:10], kind=\"linear\"\n",
    "        )\n",
    "        f_boarding_E_inv_linear = interp1d(\n",
    "            f_boarding_E(x)[0:12], x[0:12], kind=\"linear\"\n",
    "        )\n",
    "\n",
    "        # let's allocate profiles to flight\n",
    "        list_time_Pax = []\n",
    "        list_flights = []\n",
    "        list_ST = []\n",
    "        for i in range(len(filtered_data)):\n",
    "            N_flight_pax = int(filtered_data.loc[i, \"PAX_SUM FC\"])\n",
    "            STD = filtered_data.loc[i, \"Scheduled Time\"]\n",
    "            y = np.linspace(0.0001, 0.995, N_flight_pax)\n",
    "\n",
    "            if filtered_data.loc[i, \"Aircraft_Narrow/Wide\"] == \"Narrow body\":\n",
    "                temps_boarding = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_boarding_C_inv_linear(y)\n",
    "                )\n",
    "            else:\n",
    "                temps_boarding = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - f_boarding_E_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            for t in temps_boarding:\n",
    "                t = datetime.datetime(\n",
    "                    year=2020,\n",
    "                    month=10,\n",
    "                    day=13,\n",
    "                    hour=int((t % (24 * 60)) / 60),\n",
    "                    minute=int(t % 60),\n",
    "                    second=int(t % 1 * 60),\n",
    "                )\n",
    "                list_time_Pax.append(t)\n",
    "                list_flights.append(filtered_data.loc[i, \"Flight Number\"])\n",
    "                list_ST.append(filtered_data.loc[i, \"Scheduled Time\"])\n",
    "\n",
    "    # ====================================== deboarding =====================================\n",
    "    if system == \"arrivals\":\n",
    "        # read the excel with show-up profiles\n",
    "        show_up_arrival = pd.read_excel(\n",
    "            path_show_up,\n",
    "            sheet_name=r\"deboarding\",\n",
    "            header=1,\n",
    "        )\n",
    "\n",
    "        # interpolate deboarding profiles to use on schedule\n",
    "        x = show_up_arrival[\"time after STA\"].to_numpy(dtype=float)\n",
    "        yC = show_up_arrival[\"cumulative distribution code C\"].to_numpy(dtype=float)\n",
    "        yE = show_up_arrival[\"cumulative distribution code E\"].to_numpy(dtype=float)\n",
    "        fC = interp1d(x, yC, kind=\"linear\")\n",
    "        fE = interp1d(x, yE, kind=\"linear\")\n",
    "        fC_inv_linear = interp1d(fC(x)[0:3], x[0:3], kind=\"linear\")\n",
    "        fE_inv_linear = interp1d(fE(x)[0:4], x[0:4], kind=\"linear\")\n",
    "\n",
    "        # let's allocate profiles to flight\n",
    "        list_time_Pax = []\n",
    "        list_flights = []\n",
    "        list_ST = []\n",
    "        for i in range(len(filtered_data)):\n",
    "            N_flight_pax = int(filtered_data.loc[i, \"PAX_SUM FC\"])\n",
    "            STA = filtered_data.loc[i, \"Scheduled Time\"]\n",
    "            y = np.linspace(0.0001, 0.995, N_flight_pax)\n",
    "\n",
    "            if filtered_data.loc[i, \"Aircraft_Narrow/Wide\"] == \"Narrow body\":\n",
    "                temps_deboarding = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - fC_inv_linear(y)\n",
    "                )\n",
    "            else:\n",
    "                temps_deboarding = (\n",
    "                    filtered_data.loc[i, \"Scheduled Time\"].hour * 60\n",
    "                    + filtered_data.loc[i, \"Scheduled Time\"].minute\n",
    "                    - fE_inv_linear(y)\n",
    "                )\n",
    "\n",
    "            for t in temps_deboarding:\n",
    "                t = datetime.datetime(\n",
    "                    year=2020,\n",
    "                    month=10,\n",
    "                    day=13,\n",
    "                    hour=int((t % (24 * 60)) / 60),\n",
    "                    minute=int(t % 60),\n",
    "                    second=int(t % 1 * 60),\n",
    "                )\n",
    "                list_time_Pax.append(t)\n",
    "                list_flights.append(filtered_data.loc[i, \"Flight Number\"])\n",
    "                list_ST.append(filtered_data.loc[i, \"Scheduled Time\"])\n",
    "\n",
    "    if system == \"check-in\":\n",
    "        return df_Counters_final\n",
    "    else:\n",
    "        dct_Pax = {\n",
    "            \"Flight Number\": list_flights,\n",
    "            \"time\": list_time_Pax,\n",
    "            \"Scheduled Time\": list_ST,\n",
    "        }\n",
    "        df_Pax = pd.DataFrame(dct_Pax)\n",
    "        return list_time_Pax, df_Pax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d934c8b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2859f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:33:38.830574Z",
     "start_time": "2021-06-24T10:33:38.261092Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from src.utils.profiles_from_schedule import generate_dep_Pax_Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb7b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T10:34:34.007577Z",
     "start_time": "2021-06-24T10:34:24.045263Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_Pax, df_Counters = generate_dep_Pax_Counters(path_to_schedule=output_path)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:jupyter2] *",
   "language": "python",
   "name": "conda-env-jupyter2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}